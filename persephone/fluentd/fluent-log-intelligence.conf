##########################################################
### VMware Blockchain - Log Intelligence Configuration ###
##########################################################


############################################
#                 SOURCE                   #
############################################

<source>
  @type tail
  <parse>
    @type json
  </parse>
  path /var/lib/docker/containers/*/*-json.log
  pos_file /var/log/fluentd-docker.pos
  read_from_head true
  tag docker.*
  refresh_interval 5s
  enable_stat_watcher false
  @label @INPUT
</source>


############################################
#                FILTERS                   #
############################################

<label @INPUT>

  <filter docker.var.lib.docker.containers.**.*>
    @type concat
    key log
    stream_identity_key container_id
    # Alternative 1: 20:16:00.545 INFO  c.d.k.KVBCClient ... (regular log messages)
    # Alternative 2: Jan 09, 2020 8:25:45 PM io.grpc ...
    multiline_start_regexp /^\d{2}:\d{2}:\d{2}\.\d{3}|\w{3} \d{1,2}, \d{4} \d{1,2}:\d{2}:\d{2} \w{2}/
    continuous_line_regexp /^(?!\d{2}:\d{2}:\d{2}\.\d{3}|\w{3} \d{1,2}, \d{4} \d{1,2}:\d{2}:\d{2} \w{2})/
    flush_interval 15s
    # separator ""
    timeout_label @PARSE
  </filter>

  <match docker.var.lib.docker.containers.**.*>
    @type relabel
    @label @PARSE
  </match>

</label>


# Handle Docker logs split in several parts (using partial_message), and do not add new line between parts
#<filter docker.var.lib.docker.containers.**.*>
#  @type concat
#  key message
#  partial_key partial_message
#  partial_value true
#  separator ""
#</filter>


<label @PARSE>

  <filter docker.var.lib.docker.containers.**.*>
    @type parser
    key_name log
    reserve_data true
    remove_key_name_field true
    emit_invalid_record_to_error false

    <parse>
      @type multi_format

      # Concord
      <pattern>
        format regexp
        # Log pattern format: %d{%FT%H:%M:%S.%q} [%t] %-5p %c{2} %%%x%% %m [%l]%n
        # Regex after "logger" checks if an MDC map exists,
        # If it does, then extract it in a field called 'mdc'.
        # Below, all items in 'mdc' are extracted.
        expression /^(?<logtime>[^ ]+)( \[)(?<thread_id>[\d]+)(\] )(?<level>[^ ]+)( +)(?<logger>[^ ]+)( %(?<is_mdc>{)?(?(<is_mdc>)(?<mdc>[^%]*)|%))([% ]*)(?<message>.+?(?= \[))( \[)(?<method>[^\[]+)(\])$/
      </pattern>

      # DAML Ledger API
      <pattern>
        format regexp
        # Log pattern format: logtime...logger...level...method...message
        expression /^(?<logtime>[^ ]+) \[(?<logger>[^\]]+)\] (?<level>[^ ]+) (?<method>[^ ]+) - (?<message>.+)$/m
      </pattern>

      # DAML Execution Engine (and old pattern)
      <pattern>
        format regexp
        # Log pattern format: logtime...level...method...message
        # Additional non-capturing groups are to remove ANSI color characters, e.g., \u001b[34mINFO \u001b[0;39m
        expression /^(?<logtime>[^ ]*)( )(\e\[[0-9;]*m*)(?<level>[^ \\]*)( *)(\e\[[0-9;]*m*)( )(\e\[[0-9;]*m*)(?<method>[^ \\]*)( *)(\e\[[0-9;]*m*)( - )(?<message>.*)$/m
      </pattern>

      # DAML exceptions (already concatenated)
      <pattern>
        format regexp
        # Log pattern format: logtime...message
        expression /^(?<logtime>\w{3} \d{1,2}, \d{4} \d{1,2}:\d{2}:\d{2} \w{2}) (?<message>.*)$/m
      </pattern>

      # EthRpc
      <pattern>
        format json
      </pattern>

      <pattern>
        format none
      </pattern>

    </parse>
  </filter>

  # Remove Ethrpc initialization messages
  <filter docker.var.lib.docker.containers.**.*>
    @type grep
    <or>
      <exclude>
        key loggerName
        pattern /^.*springframework.*$/
      </exclude>
      <exclude>
        key uri
        pattern /^.*ctx:uri.*&/
      </exclude>
    </or>
  </filter>

  # Add fields in each log before pushing it to output
  # service_name is obtained from config.v2.json which is the container name
  # consortium_id and replica_id to be injected from environment variables as part of deployment
  # Filter out "source: stdout" key-value pair
  # It's auto-generated, and "source" is a reserved keyword in Log Insight; POST to Log Insight throws error
  <filter docker.var.lib.docker.containers.**.*>
    @type record_modifier
    <record>
      # Container name is defined in 'Name' field in container's config.v2.json. e.g /concord
      # strip off the first character /
      service_name ${id = tag_parts[5]; JSON.parse(IO.read("/var/lib/docker/containers/#{id}/config.v2.json"))['Name'][1..-1]}
      consortium_id "#{ENV['CONSORTIUM_ID']}"
      replica_id "#{ENV['REPLICA_ID']}"
    </record>
    remove_keys source,stream
  </filter>

  <match docker.var.lib.docker.containers.**.*>
    @type relabel
    @label @RELABEL
  </match>

</label>


############################################
#                OUTPUT                    #
############################################

<label @RELABEL>
  # Rename tag to service name
  <match docker.var.lib.docker.containers.**.*>
    @type rewrite_tag_filter
    <rule>
      key service_name
      pattern /^(.+)$/
      tag $1
    </rule>
  </match>

  <match *concord* *ethrpc* *daml*>
    @type relabel
    @label @OUTPUT
  </match>

</label>

<label @OUTPUT>

  <filter *concord*>
    @type record_modifier
    <record>
      _dummy_ ${if record.has_key?('mdc'); mdc_list = record['mdc'].split('}'); mdc_list.each { |x| sublist = x.split(", "); mdc_key = sublist[0].sub('{', ''); record[mdc_key] = sublist[1]; } end; nil}
      _dummy2_ ${if record.has_key?('message') and record.has_key?('cid'); record['message'] += "; correlationId=" + record['cid']; end; nil}
      correlation_id ${record['cid']}
    </record>
    remove_keys is_mdc,mdc,cid
  </filter>

  <filter *daml*>
    @type record_modifier
    <record>
      _dummy_ ${if record.has_key?('message'); msglist = record['message'].split("correlationId="); if msglist.size > 1; cidlist = msglist[1].split(' '); if cidlist.size > 0; record['correlation_id']=cidlist[0]; end; end; end; nil}
    </record>
  </filter>

  # Push matching logs to Log Intelligence
  <match *concord* *ethrpc* *daml*>

  @type http
  @id out_http_plugin
  endpoint LINT_ENDPOINT_URL
  open_timeout 120
  content_type application/json
  http_method post
  headers {"Authorization":"Bearer LINT_AUTHORIZATION_BEARER", "structure":"simple"}
  tls_verify_mode none
  <buffer>
    total_limit_size 512m
    chunk_limit_records 300
    flush_interval 3s
    flush_at_shutdown true
    flush_thread_count 4
    overflow_action drop_oldest_chunk
    retry_max_times 4
    disable_chunk_backup true
  </buffer>

 </match>

</label>
